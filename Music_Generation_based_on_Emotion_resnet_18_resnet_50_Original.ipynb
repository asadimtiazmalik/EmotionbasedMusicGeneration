{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KV8Q1-J4z2b",
        "outputId": "54be5c07-9d36-4495-8f88-d21dc86fa0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preparing the dataset**"
      ],
      "metadata": {
        "id": "o15AJaYCD1br"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k8MTm7G43Qd"
      },
      "outputs": [],
      "source": [
        "%%shell \n",
        "mkdir EmoticDataHub\n",
        "cd /content/EmoticDataHub\n",
        "unzip /content/drive/MyDrive/emotic.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCi8vneY5KNk"
      },
      "outputs": [],
      "source": [
        "%%shell \n",
        "cd /content/EmoticDataHub\n",
        "unzip Annotations.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Cloning the repo containing preprocessing and training scripts**"
      ],
      "metadata": {
        "id": "m66iPiPAD6m0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSsRQZLdTxut"
      },
      "outputs": [],
      "source": [
        "%%shell \n",
        "git clone https://github.com/Tandon-A/emotic.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Preprocessing**"
      ],
      "metadata": {
        "id": "eFbnbnNBEC0h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VpzadfhXSVg",
        "outputId": "b8d30a9b-fe9a-4626-9666-bac93f029e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Annotations\n",
            "starting label  train\n",
            " Preprocessing data. Index =  0\n",
            " Preprocessing data. Index =  1000\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            " Preprocessing data. Index =  2000\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: extra compressed data\n",
            " Preprocessing data. Index =  3000\n",
            " Preprocessing data. Index =  4000\n",
            " Preprocessing data. Index =  5000\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            " Preprocessing data. Index =  6000\n",
            " Preprocessing data. Index =  7000\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            " Preprocessing data. Index =  8000\n",
            " Preprocessing data. Index =  9000\n",
            " Preprocessing data. Index =  10000\n",
            " Preprocessing data. Index =  11000\n",
            "Corrupt JPEG data: 44 extraneous bytes before marker 0xd9\n",
            " Preprocessing data. Index =  12000\n",
            " Preprocessing data. Index =  13000\n",
            " Preprocessing data. Index =  14000\n",
            " Preprocessing data. Index =  15000\n",
            " Preprocessing data. Index =  16000\n",
            " Preprocessing data. Index =  17000\n",
            " Preprocessing data. Index =  18000\n",
            " Preprocessing data. Index =  19000\n",
            " Preprocessing data. Index =  20000\n",
            " Preprocessing data. Index =  21000\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            " Preprocessing data. Index =  22000\n",
            " Preprocessing data. Index =  23000\n",
            "81 0 359\n",
            "wrote file  /content/EmoticDataHub/emotic_pre/train.csv\n",
            "tcmalloc: large alloc 3502186496 bytes == 0x12a942000 @  0x7f0b5e9621e7 0x7f0b52ab10ce 0x7f0b52b0d715 0x7f0b52b0dd1b 0x7f0b52bae333 0x5936cc 0x548c51 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f0b5e55fc87 0x5b621a\n",
            "23266 (23266, 224, 224, 3) (23266, 128, 128, 3)\n",
            "(23266, 224, 224, 3) (23266, 128, 128, 3) (23266, 26) (23266, 3)\n",
            "completed generating train data files\n",
            "starting label  val\n",
            " Preprocessing data. Index =  0\n",
            " Preprocessing data. Index =  1000\n",
            " Preprocessing data. Index =  2000\n",
            " Preprocessing data. Index =  3000\n",
            "19 0 0\n",
            "wrote file  /content/EmoticDataHub/emotic_pre/val.csv\n",
            "3315 (3315, 224, 224, 3) (3315, 128, 128, 3)\n",
            "(3315, 224, 224, 3) (3315, 128, 128, 3) (3315, 26) (3315, 3)\n",
            "completed generating val data files\n",
            "starting label  test\n",
            " Preprocessing data. Index =  0\n",
            " Preprocessing data. Index =  1000\n",
            " Preprocessing data. Index =  2000\n",
            " Preprocessing data. Index =  3000\n",
            " Preprocessing data. Index =  4000\n",
            " Preprocessing data. Index =  5000\n",
            " Preprocessing data. Index =  6000\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            " Preprocessing data. Index =  7000\n",
            "76 0 1\n",
            "wrote file  /content/EmoticDataHub/emotic_pre/test.csv\n",
            "7203 (7203, 224, 224, 3) (7203, 128, 128, 3)\n",
            "(7203, 224, 224, 3) (7203, 128, 128, 3) (7203, 26) (7203, 3)\n",
            "completed generating test data files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%%shell \n",
        "cd /content/emotic\n",
        "python mat2py.py --data_dir /content/EmoticDataHub --generate_npy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Installing Dependancies**"
      ],
      "metadata": {
        "id": "hgoKq3sREGoh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP4aNq7CdvjD"
      },
      "outputs": [],
      "source": [
        "%%shell \n",
        "pip install tensorboardx\n",
        "pip install torchvision==0.9.0\n",
        "pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training Resnet_18 Backbone on Context model**\n",
        "\n",
        "*   Batch Size = 52\n",
        "*   Epochs = 15\n",
        "*   mAP = 0.27550\n",
        "\n"
      ],
      "metadata": {
        "id": "mlM5V79FELIX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XtFnwBXZkTL",
        "outputId": "ffc23e85-2de9-4d19-e914-7214db472ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode  train\n",
            "tcmalloc: large alloc 3502186496 bytes == 0x5b2c000 @  0x7f71e42b11e7 0x7f70f5d3c0ce 0x7f70f5d93e57 0x7f70f5d94a6f 0x7f70f5e3ac5d 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x51566f 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f71e3eaec87 0x5b621a\n",
            "train  context  (23266, 224, 224, 3) body (23266, 128, 128, 3) cat  (23266, 26) cont (23266, 3)\n",
            "val  context  (3315, 224, 224, 3) body (3315, 128, 128, 3) cat  (3315, 26) cont (3315, 3)\n",
            "train loader  448 val loader  64\n",
            "completed preparing context model\n",
            "completed preparing body model\n",
            "starting training\n",
            "epoch = 0 loss = 57201.7258 cat loss = 26762.3857 cont_loss = 87641.0660\n",
            "epoch = 0 validation loss = 5220.2206 cat loss = 5445.2323 cont loss = 4995.2090 \n",
            "epoch = 1 loss = 43657.0637 cat loss = 17914.4521 cont_loss = 69399.6753\n",
            "epoch = 1 validation loss = 5131.7385 cat loss = 5383.9678 cont loss = 4879.5093 \n",
            "epoch = 2 loss = 43314.5971 cat loss = 17880.6837 cont_loss = 68748.5105\n",
            "epoch = 2 validation loss = 5159.4017 cat loss = 5455.3729 cont loss = 4863.4304 \n",
            "epoch = 3 loss = 43269.7892 cat loss = 17834.2306 cont_loss = 68705.3478\n",
            "epoch = 3 validation loss = 5178.0669 cat loss = 5411.7744 cont loss = 4944.3594 \n",
            "epoch = 4 loss = 43260.8525 cat loss = 17851.3006 cont_loss = 68670.4044\n",
            "epoch = 4 validation loss = 5209.2848 cat loss = 5473.2679 cont loss = 4945.3016 \n",
            "epoch = 5 loss = 43166.3922 cat loss = 17791.3540 cont_loss = 68541.4304\n",
            "epoch = 5 validation loss = 4995.8985 cat loss = 5363.2422 cont loss = 4628.5547 \n",
            "epoch = 6 loss = 43170.0491 cat loss = 17802.9309 cont_loss = 68537.1672\n",
            "epoch = 6 validation loss = 5078.0816 cat loss = 5434.1578 cont loss = 4722.0053 \n",
            "epoch = 7 loss = 42738.2125 cat loss = 17740.0381 cont_loss = 67736.3869\n",
            "epoch = 7 validation loss = 5136.3396 cat loss = 5399.4552 cont loss = 4873.2239 \n",
            "epoch = 8 loss = 42513.4325 cat loss = 17740.3493 cont_loss = 67286.5158\n",
            "epoch = 8 validation loss = 5141.0960 cat loss = 5413.1694 cont loss = 4869.0225 \n",
            "epoch = 9 loss = 42477.1418 cat loss = 17731.9718 cont_loss = 67222.3118\n",
            "epoch = 9 validation loss = 5117.7987 cat loss = 5389.6509 cont loss = 4845.9466 \n",
            "epoch = 10 loss = 42450.6321 cat loss = 17706.6314 cont_loss = 67194.6328\n",
            "epoch = 10 validation loss = 5077.6835 cat loss = 5391.0499 cont loss = 4764.3171 \n",
            "epoch = 11 loss = 42419.4172 cat loss = 17692.4039 cont_loss = 67146.4305\n",
            "epoch = 11 validation loss = 5093.5907 cat loss = 5366.2026 cont loss = 4820.9788 \n",
            "epoch = 12 loss = 42392.9862 cat loss = 17706.4732 cont_loss = 67079.4992\n",
            "epoch = 12 validation loss = 5158.1614 cat loss = 5400.7213 cont loss = 4915.6016 \n",
            "epoch = 13 loss = 42391.0225 cat loss = 17699.4657 cont_loss = 67082.5793\n",
            "epoch = 13 validation loss = 5060.9380 cat loss = 5380.1888 cont loss = 4741.6872 \n",
            "epoch = 14 loss = 42266.5126 cat loss = 17692.6416 cont_loss = 66840.3835\n",
            "epoch = 14 validation loss = 5076.5461 cat loss = 5389.5420 cont loss = 4763.5502 \n",
            "completed training\n",
            "saved models\n",
            "starting testing\n",
            "completed testing\n",
            "saved mat files\n",
            "Category        Affection 0.28939\n",
            "Category            Anger 0.04246\n",
            "Category        Annoyance 0.13149\n",
            "Category     Anticipation 0.93819\n",
            "Category         Aversion 0.09591\n",
            "Category       Confidence 0.74025\n",
            "Category      Disapproval 0.11690\n",
            "Category    Disconnection 0.32464\n",
            "Category     Disquietment 0.14940\n",
            "Category  Doubt/Confusion 0.14361\n",
            "Category    Embarrassment 0.05978\n",
            "Category       Engagement 0.96824\n",
            "Category           Esteem 0.20845\n",
            "Category       Excitement 0.71722\n",
            "Category          Fatigue 0.07730\n",
            "Category             Fear 0.06281\n",
            "Category        Happiness 0.70553\n",
            "Category             Pain 0.06303\n",
            "Category            Peace 0.21712\n",
            "Category         Pleasure 0.40225\n",
            "Category          Sadness 0.07885\n",
            "Category      Sensitivity 0.06213\n",
            "Category        Suffering 0.06472\n",
            "Category         Surprise 0.12151\n",
            "Category         Sympathy 0.27369\n",
            "Category         Yearning 0.10816\n",
            "Mean AP 0.27550\n",
            "Continuous    Valence 0.70564\n",
            "Continuous    Arousal 0.88620\n",
            "Continuous  Dominance 0.89155\n",
            "Mean VAD Error 0.82780\n",
            "saved thresholds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "%%shell\n",
        "cd /content/emotic\n",
        "python main.py --mode train --data_path /content/EmoticDataHub/emotic_pre --experiment_path /content/checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training Resnet_50 Backbone on Context model**\n",
        "\n",
        "*   Batch Size = 52\n",
        "*   Epochs = 15\n",
        "*   mAP = Yet to be determined\n"
      ],
      "metadata": {
        "id": "75Bj5NPMEjGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd /content/emotic\n",
        "python main.py --mode train --data_path /content/EmoticDataHub/emotic_pre --experiment_path /content/checkpoints --context_model 'resnet50' --epochs 15 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q_oLSHsPNj3",
        "outputId": "c263d8aa-8822-48a1-8567-9d2e6870c3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode  train\n",
            "tcmalloc: large alloc 3502186496 bytes == 0x5dec000 @  0x7f211c0b01e7 0x7f202db3b0ce 0x7f202db92e57 0x7f202db93a6f 0x7f202dc39c5d 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x51566f 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f211bcadc87 0x5b621a\n",
            "train  context  (23266, 224, 224, 3) body (23266, 128, 128, 3) cat  (23266, 26) cont (23266, 3)\n",
            "val  context  (3315, 224, 224, 3) body (3315, 128, 128, 3) cat  (3315, 26) cont (3315, 3)\n",
            "train loader  448 val loader  64\n",
            "--2022-05-21 14:58:29--  http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar\n",
            "Resolving places2.csail.mit.edu (places2.csail.mit.edu)... 128.30.195.26\n",
            "Connecting to places2.csail.mit.edu (places2.csail.mit.edu)|128.30.195.26|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97270159 (93M) [application/x-tar]\n",
            "Saving to: ‘/content/checkpoints/models/resnet50_places365.pth.tar’\n",
            "\n",
            "/content/checkpoint 100%[===================>]  92.76M  26.3MB/s    in 3.5s    \n",
            "\n",
            "2022-05-21 14:58:34 (26.3 MB/s) - ‘/content/checkpoints/models/resnet50_places365.pth.tar’ saved [97270159/97270159]\n",
            "\n",
            "completed preparing context model\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100% 44.7M/44.7M [00:01<00:00, 29.0MB/s]\n",
            "completed preparing body model\n",
            "starting training\n",
            "epoch = 0 loss = 55820.4760 cat loss = 25409.2950 cont_loss = 86231.6572\n",
            "epoch = 0 validation loss = 5248.7340 cat loss = 5473.8072 cont loss = 5023.6609 \n",
            "epoch = 1 loss = 43532.0162 cat loss = 17901.6769 cont_loss = 69162.3554\n",
            "epoch = 1 validation loss = 5175.6558 cat loss = 5434.6198 cont loss = 4916.6918 \n",
            "epoch = 2 loss = 43516.4882 cat loss = 17903.4360 cont_loss = 69129.5403\n",
            "epoch = 2 validation loss = 5125.3709 cat loss = 5445.3534 cont loss = 4805.3885 \n",
            "epoch = 3 loss = 43420.1396 cat loss = 17896.7633 cont_loss = 68943.5159\n",
            "epoch = 3 validation loss = 5112.6635 cat loss = 5396.4530 cont loss = 4828.8740 \n",
            "epoch = 4 loss = 43286.5240 cat loss = 17868.4834 cont_loss = 68704.5645\n",
            "epoch = 4 validation loss = 5196.4638 cat loss = 5396.6130 cont loss = 4996.3146 \n",
            "epoch = 5 loss = 43560.1303 cat loss = 17871.9212 cont_loss = 69248.3395\n",
            "epoch = 5 validation loss = 8407.1189 cat loss = 8305.0690 cont loss = 8509.1688 \n",
            "epoch = 6 loss = 43600.2457 cat loss = 17900.3467 cont_loss = 69300.1447\n",
            "epoch = 6 validation loss = 5131.0404 cat loss = 5401.1752 cont loss = 4860.9056 \n",
            "epoch = 7 loss = 42892.4513 cat loss = 17765.4154 cont_loss = 68019.4872\n",
            "epoch = 7 validation loss = 5131.0314 cat loss = 5418.4250 cont loss = 4843.6378 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vN7Bxn6JQHMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Music Generation based on Emotion resnet 18_resnet_50_Original.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}